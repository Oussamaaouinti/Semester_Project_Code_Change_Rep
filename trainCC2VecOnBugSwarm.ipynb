{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3f49b438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bugswarm-common in ./venv/lib/python3.7/site-packages (0.1.15)\n",
      "Requirement already satisfied: requests>=2.20.0 in ./venv/lib/python3.7/site-packages (from bugswarm-common) (2.26.0)\n",
      "Requirement already satisfied: requests-cache==0.4.13 in ./venv/lib/python3.7/site-packages (from bugswarm-common) (0.4.13)\n",
      "Requirement already satisfied: CacheControl==0.12.3 in ./venv/lib/python3.7/site-packages (from bugswarm-common) (0.12.3)\n",
      "Requirement already satisfied: msgpack-python in ./venv/lib/python3.7/site-packages (from CacheControl==0.12.3->bugswarm-common) (0.5.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in ./venv/lib/python3.7/site-packages (from requests>=2.20.0->bugswarm-common) (2.0.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./venv/lib/python3.7/site-packages (from requests>=2.20.0->bugswarm-common) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.7/site-packages (from requests>=2.20.0->bugswarm-common) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.7/site-packages (from requests>=2.20.0->bugswarm-common) (2021.10.8)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/home/aouinti/semester-project-commit2vec/venv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install requiered packages\n",
    "!pip install -U bugswarm-common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c93f59f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from bugswarm.common.rest_api.database_api import DatabaseAPI\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from unidiff import PatchSet\n",
    "from typing import List\n",
    "import json\n",
    "\n",
    "session = requests.Session()\n",
    "bugswarmapi = DatabaseAPI(token=\"2vFV-ZCG70az8Fg84uNBvXw0ICnthMRvV83APgAjICY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4e77b0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \".travis.yml\": {\n",
      "        \"added_code\": [\n",
      "            \"- openjdk8\"\n",
      "        ],\n",
      "        \"removed_code\": [\n",
      "            \"- oraclejdk8\"\n",
      "        ]\n",
      "    },\n",
      "    \"README.md\": {\n",
      "        \"added_code\": [\n",
      "            \"### Final Release\",\n",
      "            \"* 1.0.0 - Released on 26 August 2019.\",\n",
      "            \"* Based on Bootstrap v3.4.0\",\n",
      "            \"* [Demo](http://gwtbootstrap3.github.io/gwtbootstrap3-demo/) - The GWTBootstrap3 1.0.0 Demo.\",\n",
      "            \"* [API Docs](http://gwtbootstrap3.github.io/gwtbootstrap3-demo/apidocs) - The GWTBootstrap3 1.0.0 API Javadoc.\"\n",
      "        ],\n",
      "        \"removed_code\": [\n",
      "            \"### Current Release\",\n",
      "            \"* 0.9.4 - Released on 21 February 2017.\",\n",
      "            \"* Based on Bootstrap v3.3.7\",\n",
      "            \"* [Demo](http://gwtbootstrap3.github.io/gwtbootstrap3-demo/) - The GWTBootstrap3 0.9.4 Demo.\",\n",
      "            \"* [API Docs](http://gwtbootstrap3.github.io/gwtbootstrap3-demo/apidocs) - The GWTBootstrap3 0.9.4 API Javadoc.\",\n",
      "            \"### Current Snapshot\",\n",
      "            \"* 1.0-SNAPSHOT\",\n",
      "            \"* [Snapshot Demo](http://gwtbootstrap3.github.io/gwtbootstrap3-demo/snapshot) - GWTBootstrap3 v1.0-SNAPSHOT Demo. (Updated after every commit)\",\n",
      "            \"* [API Docs](http://gwtbootstrap3.github.io/gwtbootstrap3-demo/snapshot/apidocs) - GWTBootstrap3 v1.0-SNAPSHOT Javadoc. (Updated after every commit)\",\n",
      "            \"\",\n",
      "            \"* [GwtBootstrap3 Google Group](https://groups.google.com/forum/?fromgroups#!forum/gwtbootstrap3) - Ask questions here.\",\n",
      "            \"* [Issues](https://github.com/gwtbootstrap3/gwtbootstrap3/issues) - File bugs here.\",\n",
      "            \"* [Contributing](https://github.com/gwtbootstrap3/gwtbootstrap3/wiki/Contributing) - Want to help by writing code?  **Awesome!!**  Please read [this](https://github.com/gwtbootstrap3/gwtbootstrap3/wiki/Contributing) first.\",\n",
      "            \"\"\n",
      "        ]\n",
      "    },\n",
      "    \"pom.xml\": {\n",
      "        \"added_code\": [],\n",
      "        \"removed_code\": [\n",
      "            \"<version>${maven-release-plugin.version}</version>\"\n",
      "        ]\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def extract_added_removed_code(hunk):\n",
    "    \"\"\"\n",
    "    Extract added and removed lines\n",
    "    \"\"\"\n",
    "    added_lines = []\n",
    "    removed_lines = []\n",
    "    for line in hunk:\n",
    "        if line.is_added:\n",
    "            added_lines.append(line.value.strip())\n",
    "        if line.is_removed:\n",
    "            removed_lines.append(line.value.strip())\n",
    "    return added_lines, removed_lines\n",
    "\n",
    "\n",
    "def get_diff(repo: str, commit_sha: str):\n",
    "    \"\"\"\n",
    "    Get a dict where keys are filename and value a dict with added_code and removed_code\n",
    "    added_code and removed_code are list of strings\n",
    "    \"\"\"\n",
    "    files = {}\n",
    "    req = session.get(f\"https://github.com/{repo}/commit/{commit_sha}.diff\")\n",
    "    patched_files = PatchSet(req.text)\n",
    "    for patched_file in patched_files:\n",
    "        filepath = patched_file.source_file[2:]  # remove a/\n",
    "        for hunk in patched_file:\n",
    "            try : \n",
    "                added_code, removed_code = extract_added_removed_code(hunk)\n",
    "                files[filepath] = {\n",
    "                    \"added_code\": added_code,\n",
    "                    \"removed_code\": removed_code\n",
    "                }\n",
    "            except : \n",
    "                continue \n",
    "    return files\n",
    "\n",
    "print(json.dumps(get_diff(\"gwtbootstrap3/gwtbootstrap3\", \"c07f968e099d963eed195c7608487c8515393657\"), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "56a20dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [01:49,  5.68it/s]\n"
     ]
    }
   ],
   "source": [
    "ids, labels, msgs, codes = [],[],[],[]\n",
    "f = open('bugswarm_json')\n",
    "# return the json data into a dictionary \n",
    "data = json.load(f)\n",
    "for i, artifact in tqdm(enumerate(data)):   \n",
    "    for job, label in [(\"failed_job\", 0), (\"passed_job\", 1)]:\n",
    "        ids.append(artifact[job][\"trigger_sha\"])\n",
    "        labels.append(label)\n",
    "        msgs.append(f\"Commit msg for {artifact[job]['trigger_sha']}\")\n",
    "        codes.append(\n",
    "            [\n",
    "                diff\n",
    "                for _, diff in get_diff(artifact[\"repo\"], artifact[job][\"trigger_sha\"]).items()\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "43ed3cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "for code in codes:\n",
    "    for file in code:\n",
    "        for key, val in file.items():\n",
    "            if not val:\n",
    "                continue\n",
    "            for i in range(len(val)):\n",
    "                val[i] = re.sub(\" +\", \" \", val[i])\n",
    "                val[i] = re.sub(r'\\t', \"\", val[i])\n",
    "data = ids,labels,msgs,codes\n",
    "bugswarm_training_dataset = open(\"oussama_output\", \"wb\")\n",
    "pickle.dump(data,bugswarm_training_dataset)\n",
    "bugswarm_training_dataset.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "131031b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of cc2vec dictionary 2\n",
      "<class 'dict'>\n",
      "['\\x1athan', '!']\n",
      "\u001athan 0\n",
      "! 1\n",
      "# 2\n",
      "$ 3\n",
      "% 4\n",
      "& 5\n",
      "' 6\n",
      "( 7\n",
      ") 8\n",
      "* 9\n"
     ]
    }
   ],
   "source": [
    "# visualization & debugging cell \n",
    "# visualize the training pickle file we just created  \n",
    "with open('oussama_output', 'rb') as f:\n",
    "    prepared_dataset = pickle.load(f) \n",
    "#print(\"length of our dataset:\", len(prepared_dataset))\n",
    "\n",
    "# visualize the training pickle file of CC2Vec\n",
    "with open('data+model/data/jit/qt_train.pkl','rb') as f1 :\n",
    "    cc2vec_dataset = pickle.load(f1) \n",
    "#print(\"length of CC2Vec dataset:\",len(cc2vec_dataset))\n",
    "\n",
    "#print(\"Compare the 2 datasets: \", \"\\n our dataset: \\n\",prepared_dataset[3][0])\n",
    "#print(  \"\\n cc2vec dataset:\" ,cc2vec_dataset[3][0])\n",
    "\n",
    "#visualize the dictionary used by CC2Vec \n",
    "with open('data+model/data/jit/qt_dict.pkl',  'rb') as f2:\n",
    "    cc2vec_dict = pickle.load(f2)\n",
    "print (\"length of cc2vec dictionary\", len(cc2vec_dict)) \n",
    "#visualizing CC2Vec dictionary elements\n",
    "print (type(cc2vec_dict[1]))\n",
    "print(list(cc2vec_dict[1])[:2])\n",
    "nb_printed_elements=0\n",
    "for k,v in cc2vec_dict[1].items() : \n",
    "    if nb_printed_elements<10 : \n",
    "        print(k,v)\n",
    "        nb_printed_elements +=1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db644945",
   "metadata": {},
   "source": [
    "# Use CC2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "71cdd2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:11<00:00,  1.18s/it]\n",
      "Training: Epoch 1 / 50 -- Total loss: 9.743361\n",
      "100%|███████████████████████████████████████████| 10/10 [00:10<00:00,  1.10s/it]\n",
      "Training: Epoch 2 / 50 -- Total loss: 9.741258\n",
      "100%|███████████████████████████████████████████| 10/10 [00:11<00:00,  1.13s/it]\n",
      "Training: Epoch 3 / 50 -- Total loss: 9.739617\n",
      "100%|███████████████████████████████████████████| 10/10 [00:10<00:00,  1.08s/it]\n",
      "Training: Epoch 4 / 50 -- Total loss: 9.738098\n",
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.20s/it]\n",
      "Training: Epoch 5 / 50 -- Total loss: 9.736253\n",
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.30s/it]\n",
      "Training: Epoch 6 / 50 -- Total loss: 9.734410\n",
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.22s/it]\n",
      "Training: Epoch 7 / 50 -- Total loss: 9.732187\n",
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.21s/it]\n",
      "Training: Epoch 8 / 50 -- Total loss: 9.730014\n",
      "100%|███████████████████████████████████████████| 10/10 [00:11<00:00,  1.17s/it]\n",
      "Training: Epoch 9 / 50 -- Total loss: 9.727187\n",
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.27s/it]\n",
      "Training: Epoch 10 / 50 -- Total loss: 9.724509\n",
      "100%|███████████████████████████████████████████| 10/10 [00:11<00:00,  1.15s/it]\n",
      "Training: Epoch 11 / 50 -- Total loss: 9.720708\n",
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.21s/it]\n",
      "Training: Epoch 12 / 50 -- Total loss: 9.716893\n",
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.27s/it]\n",
      "Training: Epoch 13 / 50 -- Total loss: 9.713275\n",
      "100%|███████████████████████████████████████████| 10/10 [00:13<00:00,  1.33s/it]\n",
      "Training: Epoch 14 / 50 -- Total loss: 9.708733\n",
      "100%|███████████████████████████████████████████| 10/10 [00:11<00:00,  1.11s/it]\n",
      "Training: Epoch 15 / 50 -- Total loss: 9.702487\n",
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.24s/it]\n",
      "Training: Epoch 16 / 50 -- Total loss: 9.695004\n",
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.26s/it]\n",
      "Training: Epoch 17 / 50 -- Total loss: 9.686049\n",
      "100%|███████████████████████████████████████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Training: Epoch 18 / 50 -- Total loss: 9.675674\n",
      "100%|███████████████████████████████████████████| 10/10 [00:10<00:00,  1.09s/it]\n",
      "Training: Epoch 19 / 50 -- Total loss: 9.663546\n",
      "100%|███████████████████████████████████████████| 10/10 [00:10<00:00,  1.08s/it]\n",
      "Training: Epoch 20 / 50 -- Total loss: 9.648742\n",
      "100%|███████████████████████████████████████████| 10/10 [00:10<00:00,  1.09s/it]\n",
      "Training: Epoch 21 / 50 -- Total loss: 9.639590\n",
      "100%|███████████████████████████████████████████| 10/10 [00:10<00:00,  1.09s/it]\n",
      "Training: Epoch 22 / 50 -- Total loss: 9.625420\n",
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.21s/it]\n",
      "Training: Epoch 23 / 50 -- Total loss: 9.606953\n",
      "100%|███████████████████████████████████████████| 10/10 [00:10<00:00,  1.08s/it]\n",
      "Training: Epoch 24 / 50 -- Total loss: 9.583185\n",
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.22s/it]\n",
      "Training: Epoch 25 / 50 -- Total loss: 9.576948\n",
      "100%|███████████████████████████████████████████| 10/10 [00:11<00:00,  1.17s/it]\n",
      "Training: Epoch 26 / 50 -- Total loss: 9.556653\n",
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.22s/it]\n",
      "Training: Epoch 27 / 50 -- Total loss: 9.536212\n",
      "100%|███████████████████████████████████████████| 10/10 [00:10<00:00,  1.10s/it]\n",
      "Training: Epoch 28 / 50 -- Total loss: 9.519797\n",
      "100%|███████████████████████████████████████████| 10/10 [00:10<00:00,  1.08s/it]\n",
      "Training: Epoch 29 / 50 -- Total loss: 9.492271\n",
      "100%|███████████████████████████████████████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Training: Epoch 30 / 50 -- Total loss: 9.483155\n",
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.26s/it]\n",
      "Training: Epoch 31 / 50 -- Total loss: 9.450235\n",
      "100%|███████████████████████████████████████████| 10/10 [00:10<00:00,  1.08s/it]\n",
      "Training: Epoch 32 / 50 -- Total loss: 9.432149\n",
      "100%|███████████████████████████████████████████| 10/10 [00:10<00:00,  1.09s/it]\n",
      "Training: Epoch 33 / 50 -- Total loss: 9.410493\n",
      "100%|███████████████████████████████████████████| 10/10 [00:10<00:00,  1.09s/it]\n",
      "Training: Epoch 34 / 50 -- Total loss: 9.391966\n",
      "100%|███████████████████████████████████████████| 10/10 [00:10<00:00,  1.09s/it]\n",
      "Training: Epoch 35 / 50 -- Total loss: 9.369659\n",
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.27s/it]\n",
      "Training: Epoch 36 / 50 -- Total loss: 9.333880\n",
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.29s/it]\n",
      "Training: Epoch 37 / 50 -- Total loss: 9.325093\n",
      "100%|███████████████████████████████████████████| 10/10 [00:11<00:00,  1.19s/it]\n",
      "Training: Epoch 38 / 50 -- Total loss: 9.307679\n",
      "100%|███████████████████████████████████████████| 10/10 [00:11<00:00,  1.15s/it]\n",
      "Training: Epoch 39 / 50 -- Total loss: 9.276828\n",
      "100%|███████████████████████████████████████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Training: Epoch 40 / 50 -- Total loss: 9.248795\n",
      "100%|███████████████████████████████████████████| 10/10 [00:10<00:00,  1.09s/it]\n",
      "Training: Epoch 41 / 50 -- Total loss: 9.222695\n",
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.23s/it]\n",
      "Training: Epoch 42 / 50 -- Total loss: 9.179645\n",
      "100%|███████████████████████████████████████████| 10/10 [00:11<00:00,  1.18s/it]\n",
      "Training: Epoch 43 / 50 -- Total loss: 9.197827\n",
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.29s/it]\n",
      "Training: Epoch 44 / 50 -- Total loss: 9.145758\n",
      "100%|███████████████████████████████████████████| 10/10 [00:10<00:00,  1.08s/it]\n",
      "Training: Epoch 45 / 50 -- Total loss: 9.169069\n",
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.22s/it]\n",
      "Training: Epoch 46 / 50 -- Total loss: 9.098577\n",
      "100%|███████████████████████████████████████████| 10/10 [00:13<00:00,  1.32s/it]\n",
      "Training: Epoch 47 / 50 -- Total loss: 9.105426\n",
      "100%|███████████████████████████████████████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Training: Epoch 48 / 50 -- Total loss: 9.091084\n",
      "100%|███████████████████████████████████████████| 10/10 [00:11<00:00,  1.12s/it]\n",
      "Training: Epoch 49 / 50 -- Total loss: 9.049883\n",
      "100%|███████████████████████████████████████████| 10/10 [00:11<00:00,  1.19s/it]\n",
      "Training: Epoch 50 / 50 -- Total loss: 9.000683\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------Finish the training process---------------------------\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2, 3'\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "!python CC2Vec/jit_cc2ftr.py -train -train_data oussama_output -test_data oussama_output -dictionary_data data+model/data/jit/qt_dict.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1140ca1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1250/1250 [04:24<00:00,  4.73it/s]\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------Finish the extracting process-------------------------\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "!python CC2Vec/jit_cc2ftr.py -predict -predict_data oussama_output -dictionary_data data+model/data/jit/qt_dict.pkl -load_model data+model/model/jit/qt_cc2ftr.pt -name oussama_output_2.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "f477b0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1250, 196)\n",
      "1250\n",
      "[0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+02\n",
      " 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02\n",
      " 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02\n",
      " 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02\n",
      " 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02\n",
      " 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02\n",
      " 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02\n",
      " 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02\n",
      " 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02\n",
      " 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02\n",
      " 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02\n",
      " 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02\n",
      " 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02\n",
      " 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+00 7.9999991e-06\n",
      " 6.8063995e+01 3.8995242e-01 0.0000000e+00 6.9123772e+01 6.9013893e+01\n",
      " 6.4589516e+01 0.0000000e+00 7.0242897e+01 6.8168098e+01 7.1736374e+01\n",
      " 0.0000000e+00 6.3964249e+01 6.5167877e+01 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 6.2039829e+01 5.7074951e+01 0.0000000e+00\n",
      " 7.2015511e+01 7.7045952e+01 0.0000000e+00 0.0000000e+00 6.0785511e+01\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 6.2928215e+01 6.7004478e+01 0.0000000e+00 7.3604103e+01\n",
      " 7.4588898e+01 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 6.7552475e+01\n",
      " 0.0000000e+00 0.0000000e+00 7.5491379e+01 0.0000000e+00 7.1417679e+01\n",
      " 7.1899796e+01 6.1690735e+01 6.9783470e+01 6.8172470e+01 0.0000000e+00\n",
      " 0.0000000e+00 6.5562843e+01 0.0000000e+00 6.9836983e+01 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 7.1542702e+01 0.0000000e+00 1.1809393e+04\n",
      " 0.0000000e+00]\n"
     ]
    }
   ],
   "source": [
    "with open('oussama_output_2.pkl', 'rb') as f:\n",
    "    extracted_vectors= pickle.load(f)\n",
    "print(extracted_vectors.shape)\n",
    "\n",
    "#showing that CC2Vec model isn't working properly \n",
    "similar_vectors=0 \n",
    "for i in range (0, extracted_vectors.shape[0]-1):\n",
    "    if extracted_vectors[i].all() ==extracted_vectors[i+1].all() : \n",
    "        similar_vectors +=1 \n",
    "print(similar_vectors+1)\n",
    "print(extracted_vectors[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
