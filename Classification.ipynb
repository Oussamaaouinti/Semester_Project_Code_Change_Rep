{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "16f34a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250\n"
     ]
    }
   ],
   "source": [
    "# Importing the vector presentation of the commits trained on CC2Vec \n",
    "import pickle\n",
    "with open('oussama_output_2.pkl', 'rb') as f:\n",
    "    out = pickle.load(f)\n",
    "# As we know in BugSwarm, each fail is followed by a success, thus we can create the labels list manually \n",
    "labels=[]\n",
    "for i in range(0,len(out)):\n",
    "    if i%2== 0: \n",
    "        labels.append(0)\n",
    "    else : \n",
    "        labels.append(1)\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "639571af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In order to test our classifier first, we fit our model to the whole dataset\n",
    "clf = svm.SVC() \n",
    "clf.fit(out, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9f6a363d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n"
     ]
    }
   ],
   "source": [
    "#checking if the classifier works ; Expected accuracy=100% \n",
    "for i in range(0,len(labels)) :\n",
    "    print(clf.predict([out[i]]), labels[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b236c5",
   "metadata": {},
   "source": [
    "#  Visualization  of returned vectors by CC2Vec Model & Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "28847733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1250, 196)\n",
      "1250\n",
      "[0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+02\n",
      " 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02\n",
      " 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02\n",
      " 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02\n",
      " 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02\n",
      " 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02\n",
      " 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02\n",
      " 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02\n",
      " 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02\n",
      " 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02\n",
      " 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02\n",
      " 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02\n",
      " 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+02\n",
      " 1.0000000e+02 1.0000000e+02 1.0000000e+02 1.0000000e+00 7.9999991e-06\n",
      " 6.8063995e+01 3.8995242e-01 0.0000000e+00 6.9123772e+01 6.9013893e+01\n",
      " 6.4589516e+01 0.0000000e+00 7.0242897e+01 6.8168098e+01 7.1736374e+01\n",
      " 0.0000000e+00 6.3964249e+01 6.5167877e+01 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 6.2039829e+01 5.7074951e+01 0.0000000e+00\n",
      " 7.2015511e+01 7.7045952e+01 0.0000000e+00 0.0000000e+00 6.0785511e+01\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 6.2928215e+01 6.7004478e+01 0.0000000e+00 7.3604103e+01\n",
      " 7.4588898e+01 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 6.7552475e+01\n",
      " 0.0000000e+00 0.0000000e+00 7.5491379e+01 0.0000000e+00 7.1417679e+01\n",
      " 7.1899796e+01 6.1690735e+01 6.9783470e+01 6.8172470e+01 0.0000000e+00\n",
      " 0.0000000e+00 6.5562843e+01 0.0000000e+00 6.9836983e+01 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 7.1542702e+01 0.0000000e+00 1.1809393e+04\n",
      " 0.0000000e+00]\n"
     ]
    }
   ],
   "source": [
    "with open('oussama_output_2.pkl', 'rb') as f:\n",
    "    extracted_vectors= pickle.load(f)\n",
    "print(extracted_vectors.shape)\n",
    "\n",
    "#showing that CC2Vec model isn't working properly \n",
    "similar_vectors=0 \n",
    "for i in range (0, extracted_vectors.shape[0]-1):\n",
    "    if extracted_vectors[i].all() ==extracted_vectors[i+1].all() : \n",
    "        similar_vectors +=1 \n",
    "print(similar_vectors+1)\n",
    "print(extracted_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59d0fc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if \"CC2Vec\" not in sys.path:\n",
    "    sys.path.append(\"CC2Vec\")\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "from jit_padding import mapping_dict_code,padding_message, clean_and_reformat_code, padding_commit_code, mapping_dict_msg, convert_msg_to_label\n",
    "from jit_cc2ftr_extracted import extracted_cc2ftr\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f00320af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('oussama_output', 'rb') as f:\n",
    "    bugswarm_dataset = pickle.load(f) \n",
    "codes= bugswarm_dataset[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "36fc5167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mofify mapping function to print number of null tokens \n",
    "def mapping_dict_code(pad_code, dict_code):\n",
    "    null_tokens = 0 \n",
    "    found_tokens = 0 \n",
    "    for commit in pad_code:\n",
    "        for file in commit:\n",
    "            for line in file:\n",
    "                for token in line.split(' '):\n",
    "                    if token.lower() in dict_code.keys():\n",
    "                        found_tokens+=1\n",
    "                    else:\n",
    "                        null_tokens +=1 \n",
    "    return (null_tokens,found_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "170d7aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null_tokens_in_added_code,found_tokens_in_added_code: (1590199, 9801)\n",
      "Percentage of null_tokens_in_aded_code:  99.3874375\n",
      "null_tokens_in_removed_code,found_tokens_in_removed_code: (1595442, 4558)\n",
      "Percentage of null_tokens_in_removed_code:  99.715125\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "@dataclass\n",
    "class Params:\n",
    "    \"\"\"Structure similar to params generated by argparse\"\"\"\n",
    "    dict_file = \"data+model/data/jit/qt_dict.pkl\"\n",
    "    msg_length = 256\n",
    "    code_file = 2\n",
    "    code_line = 10\n",
    "    code_length = 64\n",
    "    batch_size = 1\n",
    "    embed_size = 64\n",
    "    hidden_size = 32\n",
    "    dropout_keep_prob = 0.5\n",
    "    l2_reg_lambda = 1e-5\n",
    "    learning_rate = 1e-4\n",
    "    num_epochs = 50\n",
    "    load_model = \"data+model/model/jit/qt_cc2ftr.pt\"\n",
    "    name = \"output.pkl\"\n",
    "\n",
    "params = Params()\n",
    "\n",
    "with open(params.dict_file, 'rb') as fd:\n",
    "    dictionary = pickle.load(fd)   \n",
    "dict_msg, dict_code = dictionary  \n",
    "\n",
    "added_code, removed_code = clean_and_reformat_code(codes)\n",
    "\n",
    "pad_added_code = padding_commit_code(data=added_code, max_file=params.code_file, max_line=params.code_line, max_length=params.code_length)\n",
    "pad_removed_code = padding_commit_code(data=removed_code, max_file=params.code_file, max_line=params.code_line, max_length=params.code_length)\n",
    "\n",
    "\n",
    "(null_tokens_in_added_code,found_tokens_in_added_code) = mapping_dict_code(pad_code=pad_added_code, dict_code=dict_code)\n",
    "(null_tokens_in_removed_code,found_tokens_in_removed_code) = mapping_dict_code(pad_code=pad_removed_code, dict_code=dict_code)\n",
    "percentage_of_null_tokens_in_added_code = 100* null_tokens_in_added_code / (null_tokens_in_added_code+found_tokens_in_added_code) \n",
    "percentage_of_null_tokens_removed_code = 100* null_tokens_in_removed_code / (null_tokens_in_removed_code+found_tokens_in_removed_code)\n",
    "print(\"null_tokens_in_added_code,found_tokens_in_added_code:\",(null_tokens_in_added_code,found_tokens_in_added_code))\n",
    "print(\"Percentage of null_tokens_in_aded_code: \", percentage_of_null_tokens_in_added_code)\n",
    "print(\"null_tokens_in_removed_code,found_tokens_in_removed_code:\",(null_tokens_in_removed_code,found_tokens_in_removed_code))\n",
    "print(\"Percentage of null_tokens_in_removed_code: \", percentage_of_null_tokens_removed_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fb14a783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of cc2vec dictionary 2\n",
      "<class 'tuple'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "86009\n"
     ]
    }
   ],
   "source": [
    "# As the problem is in the dictionary mainly, let's have a deeper look at it\n",
    "#visualize the dictionary used by CC2Vec \n",
    "with open('data+model/data/jit/qt_dict.pkl',  'rb') as f2:\n",
    "    cc2vec_dict = pickle.load(f2)\n",
    "print (\"length of cc2vec dictionary\", len(cc2vec_dict)) \n",
    "#visualizing CC2Vec dictionary elements\n",
    "print(type(cc2vec_dict))\n",
    "print (type(cc2vec_dict[0]))\n",
    "print(type(cc2vec_dict[1]))\n",
    "print(len(cc2vec_dict[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "394076e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict0 elements: \n",
      "\n",
      "('!', 0)\n",
      "('#', 1)\n",
      "('$', 2)\n",
      "('%', 3)\n",
      "('&', 4)\n",
      "(\"'\", 5)\n",
      "(\"''\", 6)\n",
      "(\"'*\", 7)\n",
      "(\"'**/*.cpp\", 8)\n",
      "(\"'*/3rdparty/*\", 9)\n",
      "(\"'*=\", 10)\n",
      "(\"'*mid\", 11)\n",
      "(\"'*rb\", 12)\n",
      "(\"'+\", 13)\n",
      "(\"'+=\", 14)\n",
      "(\"'-\", 15)\n",
      "(\"'-1\", 16)\n",
      "(\"'-dcomplex=qvector\", 17)\n",
      "(\"'-dempty=\", 18)\n",
      "(\"'-enable-debugger\", 19)\n",
      "(\"'-icu\", 20)\n",
      "(\"'-no-stl\", 21)\n",
      "(\"'-qt-xcb\", 22)\n",
      "(\"'-typedef\", 23)\n",
      "(\"'-wno-variadic-macros\", 24)\n",
      "(\"'-wunused-private-field\", 25)\n",
      "(\"'.\", 26)\n",
      "(\"'.*copyright.*nokia\", 27)\n",
      "(\"'.*copyright.*nokia.*|.*contact\", 28)\n",
      "(\"'../\", 29)\n",
      "(\"'../main.cpp\", 30)\n",
      "(\"'./\", 31)\n",
      "(\"'.apple\", 32)\n",
      "(\"'.exe\", 33)\n",
      "(\"'.helvetica\", 34)\n",
      "(\"'.html\", 35)\n",
      "(\"'.png\", 36)\n",
      "(\"'/\", 37)\n",
      "(\"'/developer\", 38)\n",
      "(\"'/etc/passwd\", 39)\n",
      "(\"'/tmp/black.jpg\", 40)\n",
      "(\"'0xfdd0\", 41)\n",
      "(\"'200/ok\", 42)\n",
      "(\"'38\", 43)\n",
      "(\"'3rdparty\", 44)\n",
      "(\"'64\", 45)\n",
      "(\"'96.0\", 46)\n",
      "(\"':5.10\", 47)\n",
      "(\"'=\", 48)\n",
      "(\"'==\", 49)\n",
      "(\"'\\\\\", 50)\n",
      "dict1 elements \n",
      "\n",
      "('\\x1athan', 0)\n",
      "('!', 1)\n",
      "('#', 2)\n",
      "('$', 3)\n",
      "('%', 4)\n",
      "('&', 5)\n",
      "(\"'\", 6)\n",
      "('(', 7)\n",
      "(')', 8)\n",
      "('*', 9)\n",
      "('+', 10)\n",
      "(',', 11)\n",
      "('-', 12)\n",
      "('.', 13)\n",
      "('/', 14)\n",
      "('0', 15)\n",
      "('00', 16)\n",
      "('000', 17)\n",
      "('0000', 18)\n",
      "('00000', 19)\n",
      "('000000', 20)\n",
      "('0000000', 21)\n",
      "('00000000', 22)\n",
      "('000000000', 23)\n",
      "('0000000000', 24)\n",
      "('000000000000', 25)\n",
      "('000000000000000', 26)\n",
      "('00000000000000000000', 27)\n",
      "('0000000000000000000000000', 28)\n",
      "('00000000000000000000000000', 29)\n",
      "('000000000000000000000000000', 30)\n",
      "('00000000000000000000000000000000', 31)\n",
      "('0000000000000000000000000000000000000', 32)\n",
      "('0000000000000000000000000000000000000377', 33)\n",
      "('0000000000000000000000000000000000001', 34)\n",
      "('000000000000000000000000001', 35)\n",
      "('0000000000000000000000000rrrrrgg', 36)\n",
      "('000000000000000000001', 37)\n",
      "('000000000000000000rrrrrggggggbbb', 38)\n",
      "('00000000000000001988462483865600e30', 39)\n",
      "('0000000000000000f', 40)\n",
      "('000000000000001px', 41)\n",
      "('0000000000001', 42)\n",
      "('000000000000377', 43)\n",
      "('000000000000d0', 44)\n",
      "('000000000001', 45)\n",
      "('0000000000012', 46)\n",
      "('00000000000250', 47)\n",
      "('000000000004', 48)\n",
      "('00000000001', 49)\n",
      "('000000000010d0', 50)\n",
      "number of same elements in the two dict: 22625\n",
      "Percentage of elements in common between the two dict:  26.305386645583603\n"
     ]
    }
   ],
   "source": [
    "def return_n_dict_elements(dictionary,limit) :\n",
    "    counter=0 \n",
    "    n_dict_elements=[]\n",
    "    for element in dictionary.items():\n",
    "        counter+=1 \n",
    "        #print (type(element))\n",
    "        element_key= element[0]\n",
    "        element_value= element[1]\n",
    "        n_dict_elements.append([element_key,element_value])\n",
    "        if counter>limit : \n",
    "            break\n",
    "    return (n_dict_elements)\n",
    "def print_n_dict_elements(dictionary,limit) :\n",
    "    counter=0 \n",
    "    for i in dictionary.items():\n",
    "        counter+=1 \n",
    "        print(i)\n",
    "        if counter>limit : \n",
    "            break\n",
    "def return_dict_keys_from_list(list_key_value) : \n",
    "    list_keys=[] \n",
    "    for i in range(0,len(list_key_value)-1) : \n",
    "        list_keys.append(list_key_value[i][0])\n",
    "    return(list_keys) \n",
    "\n",
    "limit= 50 ; #number of elements to visualize\n",
    "dict0 = cc2vec_dict[0]\n",
    "dict1 = cc2vec_dict[1]\n",
    "print(\"dict0 elements: \\n\")\n",
    "print_n_dict_elements(dict0,limit)\n",
    "print(\"dict1 elements \\n\")\n",
    "print_n_dict_elements(dict1,limit)\n",
    "# Why a tuple? Why repeating same elements ?? \n",
    "list0 = return_n_dict_elements(dict0,limit)\n",
    "list1 = return_n_dict_elements(dict1,limit)\n",
    "# After visualizing the two dictionaries let's see the number of elements in common between both of them\n",
    "number_of_same_elements = 0 \n",
    "dict0_keys = dict0.keys()\n",
    "dict1_keys = dict1.keys()\n",
    "for i in dict0_keys :\n",
    "    if i in dict1_keys : \n",
    "        number_of_same_elements+=1 \n",
    "dict0_keys_length = len(dict0.keys()) \n",
    "Percentage_of_elements_in_common = 100 * number_of_same_elements / dict0_keys_length \n",
    "print(\"number of same elements in the two dict:\", number_of_same_elements)\n",
    "print(\"Percentage of elements in common between the two dict: \", Percentage_of_elements_in_common)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71df86b6",
   "metadata": {},
   "source": [
    "# Creation of BugSwarm dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28d503c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aouinti/semester-project-commit2vec/venv/bin/python\n",
      "1.21.5\n",
      "Requirement already satisfied: gensim in ./venv/lib/python3.7/site-packages (4.1.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in ./venv/lib/python3.7/site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in ./venv/lib/python3.7/site-packages (from gensim) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.17.0 in ./venv/lib/python3.7/site-packages (from gensim) (1.21.5)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/home/aouinti/semester-project-commit2vec/venv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/aouinti/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!which python\n",
    "import numpy\n",
    "print(numpy.__version__)\n",
    "!pip install gensim\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "23bec405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# After debugging, we figured out that the problem is mainly related to the dictionary,thus we decided to create our own dict.\n",
    "with open('oussama_output', 'rb') as f:\n",
    "    bugswarm_dataset = pickle.load(f) \n",
    "codes_dataset = bugswarm_dataset[3]  \n",
    "dict_removed_codes =\"\" \n",
    "dict_added_codes = \"\"\n",
    "dict_msges=\"\"\n",
    "for commit in codes_dataset : \n",
    "    for file in commit : \n",
    "        listed_added_code = file.get('added_code')\n",
    "        for added_line in listed_added_code : \n",
    "            dict_added_codes+= \" \"+added_line\n",
    "        listed_removed_code = file.get('removed_code')\n",
    "        for removed_line in listed_removed_code : \n",
    "            dict_removed_codes+= \" \"+removed_line\n",
    "dict_codes= dict_removed_codes + \" \"+ dict_added_codes\n",
    "dict_codes =re.sub(\" +\", \" \", dict_codes)\n",
    "dict_codes = re.sub(r'\\t', \"\", dict_codes)\n",
    "code_tokens = word_tokenize(dict_codes)\n",
    "bugswarm_dict_codes_swapped = dict(Dictionary([code_tokens]))\n",
    "bugswarm_dict_codes = dict((v,k) for k,v in bugswarm_dict_codes_swapped.items())\n",
    "bugswarm_dict_codes['<NULL>'] = 10000000000\n",
    "# for key, value in bugswarm_dict_codes.iteritems() :\n",
    "#     print (key, value)\n",
    "#Let's create our dictionary for the msges ; same principle \n",
    "msges_dataset = bugswarm_dataset[2] \n",
    "for msge in msges_dataset : \n",
    "    dict_msges+= msge + \" \" \n",
    "msges_tokens = word_tokenize(dict_msges)\n",
    "bugswarm_dict_msges_swapped = dict(Dictionary([msges_tokens]))\n",
    "bugswarm_dict_msges = dict((v,k) for k,v in bugswarm_dict_msges_swapped.items())\n",
    "print(type(dict(bugswarm_dict_msges)))\n",
    "bugswarm_dict_msges['<NULL>'] = 10000000000\n",
    "# for key, value in bugswarm_dict_msges.iteritems() :\n",
    "#     print (key, value)\n",
    "bugswarm_dict = (bugswarm_dict_msges,bugswarm_dict_codes)\n",
    "#Creation of our dictionary file \n",
    "bugswarm_dictionary_file = open(\"bugswarm_dict.pkl\", \"wb\")\n",
    "pickle.dump(bugswarm_dict,bugswarm_dictionary_file)\n",
    "bugswarm_dictionary_file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "661d4e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "! 0\n",
      "# 1\n",
      "$ 2\n",
      "% 3\n",
      "& 4\n",
      "' 5\n",
      "'' 6\n",
      "'* 7\n",
      "'********************** 8\n",
      "'*+-.0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ 9\n",
      "'*/* 10\n",
      "'+ 11\n",
      "'+DECIMAL+ 12\n",
      "'- 13\n",
      "'-2 14\n",
      "'-F 15\n",
      "'-R 16\n",
      "'-V 17\n",
      "'-assignment 18\n",
      "'-c 19\n"
     ]
    }
   ],
   "source": [
    "#visualize some elements of our new dictionary \n",
    "nb_printed_elements=0 ; \n",
    "for k,v in bugswarm_dict_codes.items() : \n",
    "    if nb_printed_elements <20 :\n",
    "        print(k,v) \n",
    "    nb_printed_elements+=1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca3b1a8",
   "metadata": {},
   "source": [
    "# Retrain CC2Vec with our dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "17a95430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.30s/it]\n",
      "Training: Epoch 1 / 50 -- Total loss: 9.726834\n",
      "100%|███████████████████████████████████████████| 10/10 [00:11<00:00,  1.17s/it]\n",
      "Training: Epoch 2 / 50 -- Total loss: 9.721526\n",
      "100%|███████████████████████████████████████████| 10/10 [00:15<00:00,  1.53s/it]\n",
      "Training: Epoch 3 / 50 -- Total loss: 9.719066\n",
      "100%|███████████████████████████████████████████| 10/10 [00:13<00:00,  1.34s/it]\n",
      "Training: Epoch 4 / 50 -- Total loss: 9.713895\n",
      "100%|███████████████████████████████████████████| 10/10 [00:11<00:00,  1.12s/it]\n",
      "Training: Epoch 5 / 50 -- Total loss: 9.709194\n",
      "100%|███████████████████████████████████████████| 10/10 [00:11<00:00,  1.12s/it]\n",
      "Training: Epoch 6 / 50 -- Total loss: 9.703722\n",
      "100%|███████████████████████████████████████████| 10/10 [00:11<00:00,  1.12s/it]\n",
      "Training: Epoch 7 / 50 -- Total loss: 9.696003\n",
      "100%|███████████████████████████████████████████| 10/10 [00:11<00:00,  1.18s/it]\n",
      "Training: Epoch 8 / 50 -- Total loss: 9.687313\n",
      "100%|███████████████████████████████████████████| 10/10 [00:11<00:00,  1.19s/it]\n",
      "Training: Epoch 9 / 50 -- Total loss: 9.683360\n",
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.21s/it]\n",
      "Training: Epoch 10 / 50 -- Total loss: 9.678995\n",
      "100%|███████████████████████████████████████████| 10/10 [00:10<00:00,  1.08s/it]\n",
      "Training: Epoch 11 / 50 -- Total loss: 9.668184\n",
      "100%|███████████████████████████████████████████| 10/10 [00:11<00:00,  1.10s/it]\n",
      "Training: Epoch 12 / 50 -- Total loss: 9.655688\n",
      "100%|███████████████████████████████████████████| 10/10 [00:11<00:00,  1.11s/it]\n",
      "Training: Epoch 13 / 50 -- Total loss: 9.646590\n",
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.27s/it]\n",
      "Training: Epoch 14 / 50 -- Total loss: 9.639926\n",
      "100%|███████████████████████████████████████████| 10/10 [00:13<00:00,  1.33s/it]\n",
      "Training: Epoch 15 / 50 -- Total loss: 9.633038\n",
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.22s/it]\n",
      "Training: Epoch 16 / 50 -- Total loss: 9.617963\n",
      "100%|███████████████████████████████████████████| 10/10 [00:11<00:00,  1.11s/it]\n",
      "Training: Epoch 17 / 50 -- Total loss: 9.608465\n",
      "100%|███████████████████████████████████████████| 10/10 [00:11<00:00,  1.13s/it]\n",
      "Training: Epoch 18 / 50 -- Total loss: 9.597115\n",
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.21s/it]\n",
      "Training: Epoch 19 / 50 -- Total loss: 9.586961\n",
      "100%|███████████████████████████████████████████| 10/10 [00:13<00:00,  1.33s/it]\n",
      "Training: Epoch 20 / 50 -- Total loss: 9.565383\n",
      "100%|███████████████████████████████████████████| 10/10 [00:11<00:00,  1.11s/it]\n",
      "Training: Epoch 21 / 50 -- Total loss: 9.554519\n",
      "100%|███████████████████████████████████████████| 10/10 [00:14<00:00,  1.47s/it]\n",
      "Training: Epoch 22 / 50 -- Total loss: 9.543119\n",
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.26s/it]\n",
      "Training: Epoch 23 / 50 -- Total loss: 9.518537\n",
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.27s/it]\n",
      "Training: Epoch 24 / 50 -- Total loss: 9.519501\n",
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.27s/it]\n",
      "Training: Epoch 25 / 50 -- Total loss: 9.511549\n",
      "100%|███████████████████████████████████████████| 10/10 [00:14<00:00,  1.48s/it]\n",
      "Training: Epoch 26 / 50 -- Total loss: 9.471073\n",
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.29s/it]\n",
      "Training: Epoch 27 / 50 -- Total loss: 9.479419\n",
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.22s/it]\n",
      "Training: Epoch 28 / 50 -- Total loss: 9.488884\n",
      "100%|███████████████████████████████████████████| 10/10 [00:10<00:00,  1.08s/it]\n",
      "Training: Epoch 29 / 50 -- Total loss: 9.420856\n",
      "100%|███████████████████████████████████████████| 10/10 [00:11<00:00,  1.15s/it]\n",
      "Training: Epoch 30 / 50 -- Total loss: 9.402610\n",
      "100%|███████████████████████████████████████████| 10/10 [00:10<00:00,  1.10s/it]\n",
      "Training: Epoch 31 / 50 -- Total loss: 9.398712\n",
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.23s/it]\n",
      "Training: Epoch 32 / 50 -- Total loss: 9.386982\n",
      "100%|███████████████████████████████████████████| 10/10 [00:11<00:00,  1.16s/it]\n",
      "Training: Epoch 33 / 50 -- Total loss: 9.353485\n",
      "100%|███████████████████████████████████████████| 10/10 [00:13<00:00,  1.35s/it]\n",
      "Training: Epoch 34 / 50 -- Total loss: 9.357921\n",
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.24s/it]\n",
      "Training: Epoch 35 / 50 -- Total loss: 9.344569\n",
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.20s/it]\n",
      "Training: Epoch 36 / 50 -- Total loss: 9.284122\n",
      "100%|███████████████████████████████████████████| 10/10 [00:11<00:00,  1.11s/it]\n",
      "Training: Epoch 37 / 50 -- Total loss: 9.266920\n",
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.21s/it]\n",
      "Training: Epoch 38 / 50 -- Total loss: 9.256258\n",
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.25s/it]\n",
      "Training: Epoch 39 / 50 -- Total loss: 9.226553\n",
      "100%|███████████████████████████████████████████| 10/10 [00:13<00:00,  1.36s/it]\n",
      "Training: Epoch 40 / 50 -- Total loss: 9.203057\n",
      "100%|███████████████████████████████████████████| 10/10 [00:11<00:00,  1.20s/it]\n",
      "Training: Epoch 41 / 50 -- Total loss: 9.200969\n",
      "100%|███████████████████████████████████████████| 10/10 [00:14<00:00,  1.46s/it]\n",
      "Training: Epoch 42 / 50 -- Total loss: 9.190663\n",
      "100%|███████████████████████████████████████████| 10/10 [00:11<00:00,  1.18s/it]\n",
      "Training: Epoch 43 / 50 -- Total loss: 9.144855\n",
      "100%|███████████████████████████████████████████| 10/10 [00:13<00:00,  1.37s/it]\n",
      "Training: Epoch 44 / 50 -- Total loss: 9.092338\n",
      "100%|███████████████████████████████████████████| 10/10 [00:13<00:00,  1.32s/it]\n",
      "Training: Epoch 45 / 50 -- Total loss: 9.077909\n",
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.22s/it]\n",
      "Training: Epoch 46 / 50 -- Total loss: 9.093421\n",
      "100%|███████████████████████████████████████████| 10/10 [00:10<00:00,  1.10s/it]\n",
      "Training: Epoch 47 / 50 -- Total loss: 9.086718\n",
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.25s/it]\n",
      "Training: Epoch 48 / 50 -- Total loss: 9.072660\n",
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.25s/it]\n",
      "Training: Epoch 49 / 50 -- Total loss: 9.015915\n",
      "100%|███████████████████████████████████████████| 10/10 [00:16<00:00,  1.65s/it]\n",
      "Training: Epoch 50 / 50 -- Total loss: 9.003936\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------Finish the training process---------------------------\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2, 3'\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "!python CC2Vec/jit_cc2ftr.py -train -train_data oussama_output -test_data oussama_output -dictionary_data bugswarm_dict.pkl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8bac8077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"CC2Vec/jit_cc2ftr.py\", line 107, in <module>\r\n",
      "    extracted_cc2ftr(data=data, params=params)\r\n",
      "  File \"/home/aouinti/semester-project-commit2vec/CC2Vec/jit_cc2ftr_extracted.py\", line 20, in extracted_cc2ftr\r\n",
      "    model.load_state_dict(torch.load(params.load_model))\r\n",
      "  File \"/home/aouinti/semester-project-commit2vec/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 845, in load_state_dict\r\n",
      "    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\r\n",
      "RuntimeError: Error(s) in loading state_dict for HierachicalRNN:\r\n",
      "\tsize mismatch for wordRNN.embed.weight: copying a param with shape torch.Size([645582, 64]) from checkpoint, the shape in current model is torch.Size([27711, 64]).\r\n",
      "\tsize mismatch for fc2.weight: copying a param with shape torch.Size([86009, 64]) from checkpoint, the shape in current model is torch.Size([623, 64]).\r\n",
      "\tsize mismatch for fc2.bias: copying a param with shape torch.Size([86009]) from checkpoint, the shape in current model is torch.Size([623]).\r\n"
     ]
    }
   ],
   "source": [
    "!python CC2Vec/jit_cc2ftr.py -predict -predict_data oussama_output -dictionary_data bugswarm_dict.pkl -load_model data+model/model/jit/qt_cc2ftr.pt -name extracted_vectors_from_bugswarm.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "b0a05682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we faced an error related to a size mismatch and we know already that the shape of the CC2Vec dictionary is 86009 \n",
    "# We try to adapt again our dictionaries by selecting random values from them \n",
    "# def resize_dict(d,size):\n",
    "#     d_rand_keys = []\n",
    "#     d_rand_values = []\n",
    "#     for k,v in d.items():\n",
    "#         d_rand_keys.append(k)\n",
    "#         d_rand_values.append(v)\n",
    "#     d_rand_keys = list(np.random.choice(d_rand_keys,size-1)) \n",
    "#     d_rand_values = list(np.random.choice(d_rand_values,size-1))\n",
    "#     d_rand_keys.append('<NULL>')\n",
    "#     d_rand_values.append(0)\n",
    "#     for i in range(0, len(d_rand_values)):\n",
    "#         try : \n",
    "#             d_rand_values[i] = int(d_rand_values[i])\n",
    "#         except : \n",
    "#             continue \n",
    "#     resized_dict = {d_rand_keys[i]: d_rand_values[i] for i in range(size)}\n",
    "#     return(resized_dict)\n",
    "# def resize_dict(d,size) :\n",
    "#     d_rand_keys = []\n",
    "#     d_rand_values = []\n",
    "#     for k,v in d.items():\n",
    "#         d_rand_keys.append(k)\n",
    "#         d_rand_values.append(v)\n",
    "#     d_rand_keys = d_rand_keys[:size-1] \n",
    "#     d_rand_values = d_rand_values[:size-1] \n",
    "#     d_rand_keys.append('<NULL>') \n",
    "#     d_rand_values.append(0)\n",
    "#     resized_dict = {d_rand_keys[i]: d_rand_values[i] for i in range(len(d_rand_keys))}\n",
    "#     print(len(d_rand_keys))\n",
    "#     return(resized_dict)\n",
    "def resize_dict(d,size) :\n",
    "    d_rand_keys = []\n",
    "    d_rand_values = []\n",
    "    for k,v in d.items():\n",
    "        d_rand_keys.append(k)\n",
    "        d_rand_values.append(v)\n",
    "    for i in range(len(d_rand_keys),size) : \n",
    "        d_rand_keys.append(i) \n",
    "        d_rand_values.append('padding_the_dictionary') \n",
    "    d_rand_keys.append('<NULL>') \n",
    "    d_rand_values.append(0)\n",
    "    resized_dict = {d_rand_keys[i] : d_rand_values[i] for i in range(len(d_rand_keys))}\n",
    "    print(len(d_rand_keys))\n",
    "    return(resized_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "5802525a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86010\n",
      "645583\n"
     ]
    }
   ],
   "source": [
    "#Creation of our new resized dictionary \n",
    "resized_msges_dict = resize_dict(bugswarm_dict[0],86009)\n",
    "resized_codes_dict = resize_dict(bugswarm_dict[1],645582)\n",
    "resized_bugswarm_dict=(resized_msges_dict,resized_codes_dict)\n",
    "\n",
    "#Creation of our resized dictionary file \n",
    "resized_bugswarm_dictionary_file = open(\"resized_bugswarm_dict.pkl\", \"wb\")\n",
    "pickle.dump(resized_bugswarm_dict,resized_bugswarm_dictionary_file)\n",
    "bugswarm_dictionary_file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "25c99575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "! 0\n",
      "# 1\n",
      "$ 2\n",
      "% 3\n",
      "& 4\n",
      "' 5\n",
      "'' 6\n",
      "'* 7\n",
      "'********************** 8\n",
      "'*+-.0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ 9\n",
      "'*/* 10\n",
      "'+ 11\n",
      "'+DECIMAL+ 12\n",
      "'- 13\n",
      "'-2 14\n",
      "'-F 15\n",
      "'-R 16\n",
      "'-V 17\n",
      "'-assignment 18\n",
      "'-c 19\n"
     ]
    }
   ],
   "source": [
    "#Let's visualize our resized dictionary \n",
    "nb_printed_elements=0 ; \n",
    "for k,v in resized_codes_dict.items() : \n",
    "    if nb_printed_elements <20 :\n",
    "        print(k,v) \n",
    "    nb_printed_elements+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a8650031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null_tokens_in_added_code,found_tokens_in_added_code: (1588777, 11223)\n",
      "Percentage of null_tokens_in_aded_code:  99.2985625\n",
      "null_tokens_in_removed_code,found_tokens_in_removed_code: (1594811, 5189)\n",
      "Percentage of null_tokens_in_removed_code:  99.6756875\n"
     ]
    }
   ],
   "source": [
    "#Let's compare the number of tokens found in our dictionary with previous results\n",
    "\n",
    "@dataclass\n",
    "class Params:\n",
    "    \"\"\"Structure similar to params generated by argparse\"\"\"\n",
    "    dict_file = \"resized_bugswarm_dict.pkl\"\n",
    "    msg_length = 256\n",
    "    code_file = 2\n",
    "    code_line = 10\n",
    "    code_length = 64\n",
    "    name = \"oussama_output.pkl\"\n",
    "\n",
    "params = Params()\n",
    "\n",
    "with open(params.dict_file, 'rb') as fd:\n",
    "    dictionary = pickle.load(fd)   \n",
    "dict_msg, dict_code = dictionary  \n",
    "\n",
    "added_code, removed_code = clean_and_reformat_code(codes)\n",
    "\n",
    "pad_added_code = padding_commit_code(data=added_code, max_file=params.code_file, max_line=params.code_line, max_length=params.code_length)\n",
    "pad_removed_code = padding_commit_code(data=removed_code, max_file=params.code_file, max_line=params.code_line, max_length=params.code_length)\n",
    "\n",
    "\n",
    "(null_tokens_in_added_code,found_tokens_in_added_code) = mapping_dict_code(pad_code=pad_added_code, dict_code=dict_code)\n",
    "(null_tokens_in_removed_code,found_tokens_in_removed_code) = mapping_dict_code(pad_code=pad_removed_code, dict_code=dict_code)\n",
    "percentage_of_null_tokens_in_added_code = 100* null_tokens_in_added_code / (null_tokens_in_added_code+found_tokens_in_added_code) \n",
    "percentage_of_null_tokens_removed_code = 100* null_tokens_in_removed_code / (null_tokens_in_removed_code+found_tokens_in_removed_code)\n",
    "print(\"null_tokens_in_added_code,found_tokens_in_added_code:\",(null_tokens_in_added_code,found_tokens_in_added_code))\n",
    "print(\"Percentage of null_tokens_in_aded_code: \", percentage_of_null_tokens_in_added_code)\n",
    "print(\"null_tokens_in_removed_code,found_tokens_in_removed_code:\",(null_tokens_in_removed_code,found_tokens_in_removed_code))\n",
    "print(\"Percentage of null_tokens_in_removed_code: \", percentage_of_null_tokens_removed_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "e3d77766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n",
      "100%|███████████████████████████████████████████| 10/10 [00:11<00:00,  1.14s/it]\n",
      "Training: Epoch 1 / 50 -- Total loss: 9.743176\n",
      "Traceback (most recent call last):\n",
      "  File \"CC2Vec/jit_cc2ftr.py\", line 82, in <module>\n",
      "    train_model(data=data, params=params)\n",
      "  File \"/home/aouinti/semester-project-commit2vec/CC2Vec/jit_cc2ftr_train.py\", line 51, in train_model\n",
      "    save(model, params.save_dir, 'epoch', epoch)\n",
      "  File \"/home/aouinti/semester-project-commit2vec/CC2Vec/jit_utils.py\", line 8, in save\n",
      "    os.makedirs(save_dir)\n",
      "  File \"/opt/anaconda3/lib/python3.7/os.py\", line 221, in makedirs\n",
      "    mkdir(name, mode)\n",
      "OSError: [Errno 28] No space left on device: 'snapshot/2022-02-08_23-07-39'\n"
     ]
    }
   ],
   "source": [
    "# Now we retrain CC2Vec on our new resized dict\n",
    "!python CC2Vec/jit_cc2ftr.py -train -train_data oussama_output -test_data oussama_output -dictionary_data resized_bugswarm_dict.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "9409bea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1%|▍                                        | 14/1250 [00:02<04:19,  4.76it/s]^C\n",
      "  1%|▍                                        | 15/1250 [00:03<04:25,  4.65it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"CC2Vec/jit_cc2ftr.py\", line 107, in <module>\n",
      "    extracted_cc2ftr(data=data, params=params)\n",
      "  File \"/home/aouinti/semester-project-commit2vec/CC2Vec/jit_cc2ftr_extracted.py\", line 34, in extracted_cc2ftr\n",
      "    commit_ftr = model.forward_commit_embeds_diff(pad_added_code, pad_removed_code, state_hunk, state_sent, state_word)            \n",
      "  File \"/home/aouinti/semester-project-commit2vec/CC2Vec/jit_cc2ftr_model.py\", line 178, in forward_commit_embeds_diff\n",
      "    x_added_code = self.forward_code(x=added_code, hid_state=hid_state)\n",
      "  File \"/home/aouinti/semester-project-commit2vec/CC2Vec/jit_cc2ftr_model.py\", line 137, in forward_code\n",
      "    sent, state_word = self.wordRNN(torch.cuda.LongTensor(words).view(-1, self.batch_size), hid_state_word)\n",
      "  File \"/home/aouinti/semester-project-commit2vec/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 547, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/aouinti/semester-project-commit2vec/CC2Vec/jit_cc2ftr_model.py\", line 45, in forward\n",
      "    sent = attention_mul(out_state, attn)\n",
      "  File \"/home/aouinti/semester-project-commit2vec/CC2Vec/jit_cc2ftr_model.py\", line 14, in attention_mul\n",
      "    h_i = a_i * h_i\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Now we try to extract vectors presentation of code from \n",
    "!python CC2Vec/jit_cc2ftr.py -predict -predict_data oussama_output -dictionary_data resized_bugswarm_dict.pkl -load_model data+model/model/jit/qt_cc2ftr.pt -name extracted_vectors_from_bugswarm.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90890a13",
   "metadata": {},
   "source": [
    "# Build Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a7265042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.488"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build Classification using :  SVM \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "with open('extracted_vectors_from_bugswarm.pkl', 'rb') as f:\n",
    "    extracted_vectors_from_bugswarm= pickle.load(f)\n",
    "X, y = extracted_vectors_from_bugswarm,labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42,test_size=0.2)\n",
    "pipe = make_pipeline(StandardScaler(), SVC())\n",
    "pipe.fit(X_train, y_train)  # apply scaling on training data\n",
    "pipe.score(X_test, y_test)  # apply scaling on testing data, without leaking training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4361cd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.953125\n",
      "-1.0491803278688523\n"
     ]
    }
   ],
   "source": [
    "# Build Classification using : Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# we will first use 10 estimators and a maximum depth of 3 levels.\n",
    "n_estimators = 10\n",
    "max_depth = 3\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=n_estimators, max_depth=max_depth, random_state=10\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "r2_score(y_test, y_pred)\n",
    "print(r2_score(y_test, y_pred))\n",
    "\n",
    "#Fine Tuning Random Forest hyperparametrs : \n",
    "hyperparameters = { 'randomforestclassifier__max_depth': [None, 5, 3, 1]}\n",
    "pipeline = make_pipeline(StandardScaler(), \n",
    "                         RandomForestClassifier(n_estimators=100))\n",
    "clf = GridSearchCV(pipeline, hyperparameters, cv=10)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.best_params_\n",
    "y_pred = clf.predict(X_test)\n",
    "print (r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8af4eafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn_classifier(\n",
      "  (fc1): Linear(in_features=196, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=512, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc4): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc5): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Build Classification using : A neural network \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "class nn_classifier(nn.Module) : \n",
    "    def __init__(self):\n",
    "        super(nn_classifier,self).__init__() \n",
    "        self.fc1 = nn.Linear(196,256)\n",
    "        self.fc2 = nn.Linear(256,512) \n",
    "        self.fc3 = nn.Linear(512,256)\n",
    "        self.fc4= nn.Linear(256,128) \n",
    "        self.fc5=nn.Linear(128,1) \n",
    "    def forward(self,x) : \n",
    "        x= F.relu(self.fc1(x))\n",
    "        x= F.relu(self.fc2(x))\n",
    "        x= F.relu(self.fc3(x))\n",
    "        x= F.relu(self.fc4(x))\n",
    "        x= self.fc5(x) \n",
    "        return x \n",
    "\n",
    "net= nn_classifier()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f29b0886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim \n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d3e0bf56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 196])\n",
      "torch.Size([10000, 1])\n",
      "torch.Size([10000, 196])\n",
      "torch.Size([10000, 1])\n"
     ]
    }
   ],
   "source": [
    "#As we had issues, we created data manually just to test our neural network while solving issues with the dataset\n",
    "import torch \n",
    "train_X = torch.randn(10000,196)\n",
    "print(train_X.shape)\n",
    "train_y = torch.randn(10000,1)\n",
    "print (train_Y.shape)\n",
    "test_X = torch.randn(1000,196)\n",
    "print(train_X.shape)\n",
    "test_y = torch.randn(1000,1)\n",
    "print (train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a8b70030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0. Loss 0.3933623135089874\n",
      "EPOCH: 1. Loss 0.38493362069129944\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_989519/2991749829.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"EPOCH: {epoch}. Loss {loss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/semester-project-commit2vec/venv/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training our neural network \n",
    "BATCH_SIZE = 10 \n",
    "EPOCHS = 100 \n",
    "for epoch in range (EPOCHS) : \n",
    "    for i in range (0,len(train_X),BATCH_SIZE) : \n",
    "        batch_X = train_X [i:i+BATCH_SIZE].view(BATCH_SIZE,196)\n",
    "        batch_y = train_y [i:i+BATCH_SIZE].view(BATCH_SIZE,1) \n",
    "        net.zero_grad()\n",
    "        y_hat=net(batch_X)\n",
    "        #y_hat=y_hat.long()\n",
    "        loss = criterion(y_hat,batch_y)\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "    print(f\"EPOCH: {epoch}. Loss {loss}\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "828b62c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "0.0 0.06776289\n",
      "1.0 -1.4190283\n",
      "-0.0 -1.0215809\n",
      "-0.0 -1.5614736\n",
      "0.0 0.22404684\n",
      "1.0 0.92908025\n",
      "-0.0 -0.88045603\n",
      "-0.0 -1.7172761\n",
      "-0.0 -0.6483883\n",
      "0.0 1.9449737\n",
      "1.0 -0.612259\n",
      "1.0 0.011682736\n",
      "-0.0 -0.12692516\n",
      "-0.0 -0.6145477\n",
      "-0.0 -0.5620704\n",
      "1.0 0.95066714\n",
      "1.0 0.67251265\n",
      "-0.0 0.078568526\n",
      "1.0 1.4902257\n",
      "0.0 0.4493923\n",
      "2.0 -3.0006833\n",
      "-0.0 -0.014856647\n",
      "0.0 -1.1445229\n",
      "1.0 -0.8565357\n",
      "-1.0 -1.1769042\n",
      "-1.0 -0.9392816\n",
      "1.0 0.8352597\n",
      "0.0 -1.6311257\n",
      "1.0 -2.2211397\n",
      "1.0 1.5018494\n",
      "-0.0 0.19917539\n",
      "-0.0 0.3498785\n",
      "-0.0 -0.35720438\n",
      "-1.0 -0.90036184\n",
      "0.0 0.9897792\n",
      "-1.0 -0.61602134\n",
      "1.0 -0.923988\n",
      "0.0 0.1702553\n",
      "-0.0 -0.3209195\n",
      "1.0 0.90999\n",
      "-0.0 -1.3651179\n",
      "-0.0 -0.66295725\n",
      "-1.0 -1.6974438\n",
      "-0.0 0.10552458\n",
      "-1.0 0.49761364\n",
      "1.0 -1.0383537\n",
      "-1.0 -0.9051472\n",
      "-0.0 0.2938576\n",
      "-3.0 -1.9384663\n",
      "1.0 0.9831103\n",
      "1.0 -0.276859\n",
      "-1.0 0.052388497\n",
      "2.0 -1.6947571\n",
      "-0.0 -0.45319903\n",
      "-0.0 0.7164817\n",
      "-1.0 -0.37724948\n",
      "1.0 0.0015046446\n",
      "1.0 -0.81268644\n",
      "1.0 0.022411034\n",
      "1.0 -0.6576595\n",
      "0.0 1.0964246\n",
      "1.0 -0.58227074\n",
      "1.0 -1.8974893\n",
      "1.0 -1.105304\n",
      "-1.0 -0.156967\n",
      "0.0 -0.0030309893\n",
      "0.0 -0.72273755\n",
      "-1.0 -0.60352033\n",
      "-1.0 0.8210693\n",
      "-0.0 -0.33132547\n",
      "-0.0 0.8674054\n",
      "2.0 1.4466044\n",
      "0.0 0.045223076\n",
      "1.0 -1.0381273\n",
      "-0.0 2.5372682\n",
      "-0.0 0.7951986\n",
      "-1.0 -0.54404175\n",
      "1.0 -1.1732683\n",
      "-1.0 1.3933833\n",
      "-1.0 0.16606842\n",
      "0.0 -0.6194182\n",
      "-0.0 0.5644159\n",
      "1.0 -0.30210128\n",
      "2.0 0.1426078\n",
      "1.0 1.0066856\n",
      "0.0 0.47935277\n",
      "-0.0 0.17869222\n",
      "0.0 -0.49253118\n",
      "0.0 0.6770233\n",
      "1.0 0.29392275\n",
      "-1.0 -0.4511044\n",
      "-0.0 -0.20502627\n",
      "0.0 -1.881091\n",
      "0.0 -1.686743\n",
      "0.0 -0.8518343\n",
      "0.0 -0.068168834\n",
      "2.0 1.04074\n",
      "0.0 0.7738317\n",
      "1.0 0.9296125\n",
      "0.0 -0.8528337\n",
      "-0.0 0.24984516\n",
      "-1.0 -1.0143561\n",
      "0.0 -1.0335656\n",
      "1.0 -1.4585311\n",
      "-1.0 -0.3983844\n",
      "1.0 -1.7845405\n",
      "-0.0 0.16793574\n",
      "-1.0 -0.33439615\n",
      "1.0 -1.319222\n",
      "1.0 -0.28850624\n",
      "-0.0 1.82343\n",
      "0.0 -0.7160287\n",
      "-0.0 1.2994876\n",
      "1.0 -0.8209601\n",
      "1.0 1.3256614\n",
      "-0.0 -0.505635\n",
      "-2.0 1.2602421\n",
      "-0.0 -0.60546345\n",
      "0.0 2.201151\n",
      "0.0 -1.1283292\n",
      "1.0 -1.8431479\n",
      "0.0 0.35431418\n",
      "-1.0 0.7937558\n",
      "0.0 -1.1522661\n",
      "1.0 -0.3382532\n",
      "1.0 -2.019465\n",
      "0.0 0.7080627\n",
      "-2.0 -0.36995894\n",
      "1.0 -0.53588945\n",
      "-1.0 -1.0638137\n",
      "1.0 -0.04791893\n",
      "1.0 0.53283733\n",
      "-0.0 -1.6841886\n",
      "-1.0 0.64173\n",
      "-0.0 1.132993\n",
      "1.0 0.22052221\n",
      "-0.0 -0.67279685\n",
      "1.0 -0.6509905\n",
      "-0.0 1.3858758\n",
      "1.0 0.2404918\n",
      "0.0 0.38608006\n",
      "0.0 -0.96201736\n",
      "-2.0 -1.0903563\n",
      "1.0 0.45001948\n",
      "-1.0 0.108771674\n",
      "-0.0 -1.3880132\n",
      "1.0 1.4602466\n",
      "-0.0 -0.203338\n",
      "-1.0 0.9819196\n",
      "1.0 1.3433126\n",
      "-0.0 -1.0393279\n",
      "-1.0 -0.08431385\n",
      "0.0 0.8324306\n",
      "1.0 -1.0597022\n",
      "1.0 0.638473\n",
      "1.0 -0.14513627\n",
      "1.0 -0.46034348\n",
      "2.0 -0.04923202\n",
      "1.0 0.3108315\n",
      "0.0 -0.39670223\n",
      "2.0 0.98464435\n",
      "-2.0 0.12205645\n",
      "1.0 -0.035103865\n",
      "2.0 -0.67958874\n",
      "1.0 0.3323368\n",
      "0.0 -0.19885685\n",
      "2.0 1.0470028\n",
      "-1.0 -0.6219001\n",
      "1.0 0.4555453\n",
      "-0.0 0.08171462\n",
      "-1.0 -0.4998537\n",
      "1.0 -2.1532125\n",
      "0.0 -0.47017717\n",
      "1.0 0.08418097\n",
      "-0.0 -0.91914636\n",
      "1.0 -1.5001343\n",
      "-0.0 1.2461323\n",
      "1.0 -1.2538322\n",
      "-0.0 -0.09483116\n",
      "-0.0 1.3832533\n",
      "0.0 1.1957718\n",
      "0.0 1.954659\n",
      "0.0 -2.2352023\n",
      "1.0 -1.0348644\n",
      "1.0 -0.05874328\n",
      "2.0 -1.2716165\n",
      "0.0 -0.46337742\n",
      "1.0 -1.2780062\n",
      "0.0 1.3663199\n",
      "-0.0 -1.982012\n",
      "1.0 0.7280829\n",
      "0.0 -0.17153107\n",
      "-1.0 0.02016713\n",
      "1.0 -2.2128105\n",
      "0.0 -0.14010671\n",
      "1.0 -0.32287708\n",
      "1.0 -0.13676748\n",
      "-0.0 0.593018\n",
      "1.0 0.45213115\n",
      "-0.0 -1.2773445\n",
      "0.0 -1.3966501\n",
      "-1.0 -1.3991396\n",
      "1.0 2.3343923\n",
      "1.0 0.9160633\n",
      "1.0 -1.7562524\n",
      "-0.0 -0.27801692\n",
      "-0.0 -1.2154531\n",
      "0.0 -0.11413836\n",
      "0.0 0.47193655\n",
      "-0.0 -1.856427\n",
      "1.0 0.6620674\n",
      "1.0 1.4724904\n",
      "1.0 0.2833223\n",
      "1.0 -2.6979113\n",
      "0.0 0.2917765\n",
      "1.0 1.0829109\n",
      "-1.0 0.6412724\n",
      "1.0 0.7786134\n",
      "1.0 1.0627\n",
      "0.0 1.2995204\n",
      "-1.0 0.5042641\n",
      "1.0 0.64143866\n",
      "0.0 -2.7994778\n",
      "-0.0 0.3793087\n",
      "0.0 -0.46747997\n",
      "-0.0 -1.5375997\n",
      "-0.0 1.285827\n",
      "0.0 -0.36004\n",
      "1.0 -2.927322\n",
      "-0.0 1.1922247\n",
      "-1.0 -2.360839\n",
      "-0.0 -0.5130551\n",
      "0.0 0.31137118\n",
      "-0.0 0.28642344\n",
      "-0.0 0.8442235\n",
      "-1.0 1.9142939\n",
      "1.0 -0.07815255\n",
      "0.0 -0.30090827\n",
      "1.0 0.20080152\n",
      "-0.0 -1.0826412\n",
      "0.0 -0.32740346\n",
      "1.0 1.5109515\n",
      "0.0 -0.83214384\n",
      "1.0 -2.4445968\n",
      "-1.0 -0.22470854\n",
      "-0.0 -1.2572663\n",
      "0.0 1.1218216\n",
      "-0.0 1.0732523\n",
      "-1.0 0.12307692\n",
      "0.0 -1.2260941\n",
      "-1.0 -0.3704421\n",
      "1.0 -0.17711751\n",
      "-1.0 1.4255371\n",
      "1.0 0.13959539\n",
      "1.0 0.3326718\n",
      "0.0 0.30697215\n",
      "1.0 0.1047301\n",
      "1.0 0.37902433\n",
      "0.0 0.5145332\n",
      "2.0 0.38437867\n",
      "2.0 -1.6178806\n",
      "-1.0 -0.062475994\n",
      "1.0 -0.98158497\n",
      "1.0 0.19772176\n",
      "-2.0 -1.5543292\n",
      "0.0 -1.0234716\n",
      "1.0 0.17421977\n",
      "2.0 -0.69077444\n",
      "1.0 0.52127236\n",
      "-0.0 -1.6736645\n",
      "-0.0 0.37106764\n",
      "-0.0 -0.99070024\n",
      "-0.0 -1.0055218\n",
      "0.0 -0.85181427\n",
      "1.0 -0.12423626\n",
      "-0.0 -1.3596107\n",
      "1.0 0.12663232\n",
      "1.0 -1.1243087\n",
      "0.0 -0.43474728\n",
      "0.0 0.16474918\n",
      "0.0 0.7274841\n",
      "1.0 -1.2802552\n",
      "-0.0 1.381406\n",
      "-0.0 0.53084326\n",
      "-0.0 -0.78410023\n",
      "-0.0 -0.11275163\n",
      "2.0 -0.4407005\n",
      "-0.0 -0.6170941\n",
      "-0.0 0.7975773\n",
      "1.0 -0.010289434\n",
      "1.0 0.056969937\n",
      "-0.0 0.29668728\n",
      "-0.0 0.7565551\n",
      "-1.0 -0.20077133\n",
      "-0.0 -0.6485474\n",
      "-0.0 -0.94963264\n",
      "-0.0 -0.15242541\n",
      "0.0 2.0948634\n",
      "-1.0 1.4950624\n",
      "1.0 -0.3222469\n",
      "1.0 -1.9286605\n",
      "1.0 -1.0965996\n",
      "0.0 -2.1226115\n",
      "-1.0 0.5070684\n",
      "1.0 -0.30076367\n",
      "1.0 0.54945916\n",
      "-1.0 -0.064093545\n",
      "-0.0 0.1291712\n",
      "-0.0 -0.7522575\n",
      "1.0 -1.8705338\n",
      "-0.0 -1.0398803\n",
      "1.0 0.08618697\n",
      "-0.0 -1.0076976\n",
      "-0.0 -0.5108404\n",
      "-1.0 0.7843721\n",
      "2.0 0.27806804\n",
      "1.0 0.12258394\n",
      "1.0 -0.23186558\n",
      "-0.0 -0.12481484\n",
      "-1.0 -0.21422717\n",
      "-0.0 0.9390511\n",
      "-0.0 -1.101867\n",
      "-1.0 0.76267695\n",
      "-0.0 -0.64419216\n",
      "0.0 -0.1648252\n",
      "0.0 -1.0933297\n",
      "0.0 -1.0347713\n",
      "-0.0 0.87397784\n",
      "-1.0 0.085424684\n",
      "-1.0 -0.82773465\n",
      "-1.0 -0.33779433\n",
      "0.0 1.9077018\n",
      "-1.0 -0.55665636\n",
      "-3.0 -0.5577996\n",
      "-0.0 1.1607021\n",
      "-0.0 -1.4647946\n",
      "-1.0 -1.0436231\n",
      "0.0 0.20426747\n",
      "-0.0 -0.3039339\n",
      "-1.0 -0.011976149\n",
      "-1.0 1.9361713\n",
      "-1.0 -0.20907895\n",
      "-0.0 -1.1037135\n",
      "2.0 1.4136585\n",
      "-0.0 0.005352553\n",
      "0.0 0.13633053\n",
      "-0.0 -0.8507617\n",
      "-1.0 1.9710265\n",
      "1.0 -1.2721627\n",
      "-1.0 0.56250954\n",
      "2.0 -1.2126096\n",
      "1.0 -0.4048665\n",
      "-0.0 0.5221393\n",
      "0.0 1.3142704\n",
      "-0.0 0.92107785\n",
      "0.0 1.8424695\n",
      "-0.0 1.6401845\n",
      "0.0 1.1718024\n",
      "-1.0 0.93719757\n",
      "-2.0 1.175899\n",
      "0.0 0.8436515\n",
      "1.0 -0.59022963\n",
      "1.0 -0.70223653\n",
      "0.0 0.70489407\n",
      "0.0 2.029588\n",
      "-0.0 1.4297673\n",
      "1.0 0.8076722\n",
      "-1.0 0.26380396\n",
      "-0.0 0.03647172\n",
      "1.0 -1.012902\n",
      "-1.0 -0.0029658393\n",
      "0.0 1.3854597\n",
      "1.0 -0.33134767\n",
      "-0.0 -0.059403986\n",
      "-1.0 0.16207094\n",
      "-0.0 -0.85924536\n",
      "0.0 0.7719947\n",
      "0.0 -0.58122474\n",
      "1.0 -1.2608627\n",
      "0.0 -0.34342256\n",
      "1.0 -0.40463862\n",
      "1.0 1.1947676\n",
      "0.0 0.52405226\n",
      "-2.0 -1.2781836\n",
      "0.0 -0.269105\n",
      "-0.0 -0.9276579\n",
      "1.0 -0.16194376\n",
      "-2.0 -0.399507\n",
      "0.0 -1.063695\n",
      "3.0 -0.87015295\n",
      "0.0 -0.9067456\n",
      "1.0 -1.2393957\n",
      "0.0 -0.42314038\n",
      "-0.0 0.17932594\n",
      "3.0 0.26064456\n",
      "-0.0 0.47541043\n",
      "-1.0 1.4178216\n",
      "0.0 0.24558927\n",
      "1.0 0.049951695\n",
      "0.0 -0.49441168\n",
      "-0.0 0.13743748\n",
      "1.0 1.1032581\n",
      "-0.0 0.64556086\n",
      "0.0 0.54377294\n",
      "0.0 -0.97256786\n",
      "-2.0 1.3075011\n",
      "0.0 0.8756831\n",
      "1.0 -1.0320209\n",
      "-0.0 -0.6899781\n",
      "-1.0 -0.3019122\n",
      "-1.0 -0.5489725\n",
      "0.0 -0.3803164\n",
      "1.0 1.7894462\n",
      "0.0 -0.13537332\n",
      "-0.0 0.6427375\n",
      "0.0 -1.4396611\n",
      "1.0 0.5808133\n",
      "-1.0 -0.5389797\n",
      "0.0 -0.697569\n",
      "1.0 -2.0484188\n",
      "2.0 0.82174164\n",
      "-0.0 1.0590239\n",
      "1.0 -1.3682799\n",
      "-1.0 -1.9928025\n",
      "-0.0 -0.6504835\n",
      "0.0 1.1346729\n",
      "1.0 1.970608\n",
      "1.0 1.8855922\n",
      "-0.0 -0.21673459\n",
      "0.0 1.4841218\n",
      "0.0 -0.05135546\n",
      "-0.0 1.3508093\n",
      "0.0 0.16064909\n",
      "1.0 0.016937535\n",
      "1.0 -0.32051638\n",
      "0.0 -1.2363791\n",
      "-2.0 -1.0136018\n",
      "-0.0 -0.10138867\n",
      "-0.0 -1.1066179\n",
      "-1.0 -1.4795756\n",
      "-0.0 0.61539143\n",
      "0.0 -0.5661849\n",
      "-0.0 -2.7743666\n",
      "1.0 -0.25236535\n",
      "0.0 -0.2711916\n",
      "-2.0 -1.3267919\n",
      "1.0 -1.0163217\n",
      "1.0 -1.2940643\n",
      "0.0 -1.939154\n",
      "-0.0 -0.8897597\n",
      "0.0 -1.4068173\n",
      "0.0 0.6807675\n",
      "0.0 -0.30402198\n",
      "1.0 -0.12270986\n",
      "-0.0 1.2485448\n",
      "-0.0 -0.19415876\n",
      "-0.0 0.00699908\n",
      "1.0 -2.1100228\n",
      "-0.0 -1.349888\n",
      "-1.0 1.1484017\n",
      "1.0 1.5611042\n",
      "0.0 0.0807853\n",
      "0.0 0.25823766\n",
      "1.0 -0.5015291\n",
      "1.0 1.4781573\n",
      "0.0 0.22840871\n",
      "-1.0 -1.2515163\n",
      "1.0 1.4294657\n",
      "-0.0 -1.1699494\n",
      "-1.0 -0.8505596\n",
      "-0.0 1.213028\n",
      "1.0 0.8026657\n",
      "-1.0 0.019906843\n",
      "-1.0 -0.58285016\n",
      "-0.0 1.7350899\n",
      "1.0 -0.9191899\n",
      "0.0 -1.3465049\n",
      "-0.0 -0.032135338\n",
      "-2.0 -1.9664099\n",
      "1.0 -0.5159167\n",
      "0.0 -0.46109033\n",
      "-0.0 -0.31610012\n",
      "0.0 2.4040356\n",
      "0.0 1.1830974\n",
      "-1.0 0.71905464\n",
      "1.0 -0.25434756\n",
      "1.0 1.2315784\n",
      "-0.0 1.2367314\n",
      "-1.0 1.7195746\n",
      "0.0 0.79026\n",
      "-1.0 1.9124135\n",
      "-0.0 -0.14069226\n",
      "-0.0 0.14176868\n",
      "1.0 0.7942761\n",
      "-0.0 1.0080593\n",
      "0.0 -0.719839\n",
      "1.0 0.13441077\n",
      "2.0 -0.15511225\n",
      "1.0 -1.2535172\n",
      "-1.0 0.05585857\n",
      "1.0 -0.25696078\n",
      "1.0 1.0363556\n",
      "-1.0 0.15905313\n",
      "1.0 0.7302264\n",
      "1.0 -0.232319\n",
      "1.0 -0.9240394\n",
      "1.0 -1.0206022\n",
      "1.0 -1.1209903\n",
      "1.0 0.97234654\n",
      "0.0 -1.7711729\n",
      "-2.0 0.8203752\n",
      "-0.0 -1.0345341\n",
      "1.0 -0.7714527\n",
      "1.0 0.75402445\n",
      "1.0 -0.7668258\n",
      "-0.0 0.25230432\n",
      "1.0 1.2248759\n",
      "0.0 0.023764005\n",
      "2.0 0.5891665\n",
      "1.0 0.5959679\n",
      "-0.0 -0.16738021\n",
      "-0.0 1.154651\n",
      "2.0 -0.914258\n",
      "-1.0 -1.2283683\n",
      "-0.0 -0.18373723\n",
      "0.0 0.16433826\n",
      "0.0 2.0298555\n",
      "0.0 -0.25012743\n",
      "1.0 -0.40955213\n",
      "0.0 -0.02839319\n",
      "1.0 -1.2456095\n",
      "-0.0 -0.42644364\n",
      "-0.0 -1.5254649\n",
      "0.0 0.85566545\n",
      "0.0 -0.1775897\n",
      "-0.0 -1.0089324\n",
      "1.0 -1.3073028\n",
      "0.0 -0.61573416\n",
      "-0.0 -1.0813699\n",
      "2.0 -0.5551144\n",
      "1.0 0.49849445\n",
      "0.0 0.42011717\n",
      "1.0 -0.049846683\n",
      "1.0 0.299076\n",
      "0.0 1.9557244\n",
      "1.0 -1.5509852\n",
      "1.0 -0.43272233\n",
      "1.0 -1.0683783\n",
      "1.0 -0.6731311\n",
      "-0.0 -0.9229024\n",
      "1.0 -0.16489424\n",
      "-0.0 -0.028606191\n",
      "-0.0 1.684492\n",
      "1.0 0.5808972\n",
      "0.0 -0.5274095\n",
      "1.0 0.021161094\n",
      "1.0 0.50586784\n",
      "-1.0 0.28629127\n",
      "1.0 -1.0877235\n",
      "0.0 0.74550915\n",
      "-0.0 0.32964373\n",
      "-0.0 0.8030604\n",
      "0.0 -0.2984748\n",
      "1.0 -2.0810375\n",
      "1.0 0.48782167\n",
      "0.0 1.8488165\n",
      "1.0 -1.4128804\n",
      "0.0 -0.0627207\n",
      "1.0 -0.6074694\n",
      "0.0 -0.37891915\n",
      "-1.0 0.49535283\n",
      "1.0 -0.1355104\n",
      "1.0 -0.20157334\n",
      "-1.0 0.6498895\n",
      "0.0 -1.6190475\n",
      "0.0 -0.58100146\n",
      "-0.0 -0.73354614\n",
      "-0.0 -0.05378324\n",
      "0.0 -0.76323026\n",
      "1.0 -0.47332343\n",
      "-1.0 2.304012\n",
      "-0.0 0.79085034\n",
      "2.0 0.3429816\n",
      "2.0 0.06726202\n",
      "1.0 0.19054608\n",
      "-0.0 1.1010162\n",
      "-0.0 -0.91990024\n",
      "-0.0 -0.06842343\n",
      "1.0 0.3548179\n",
      "1.0 0.9186169\n",
      "-0.0 0.17885852\n",
      "1.0 1.1877064\n",
      "1.0 -0.14793342\n",
      "2.0 0.28700423\n",
      "1.0 -1.7847087\n",
      "0.0 1.5479883\n",
      "2.0 0.12615319\n",
      "0.0 -0.61499405\n",
      "1.0 -0.3909462\n",
      "-0.0 -1.2500869\n",
      "1.0 1.0197753\n",
      "1.0 0.6709446\n",
      "1.0 -0.52292407\n",
      "-0.0 0.4093875\n",
      "-1.0 -1.1051114\n",
      "-0.0 -1.2645379\n",
      "1.0 -0.14879411\n",
      "0.0 0.29385978\n",
      "1.0 1.3389553\n",
      "-0.0 0.53355175\n",
      "0.0 -1.1068277\n",
      "1.0 0.7342212\n",
      "1.0 0.19057105\n",
      "-0.0 0.37135816\n",
      "0.0 -0.50305074\n",
      "1.0 -0.4352039\n",
      "-1.0 -2.3215518\n",
      "1.0 1.4303192\n",
      "0.0 1.6666197\n",
      "1.0 1.0503356\n",
      "-0.0 0.31796506\n",
      "-0.0 -0.069987126\n",
      "-0.0 2.1619341\n",
      "-1.0 1.6060691\n",
      "1.0 0.0034694287\n",
      "-0.0 0.12532292\n",
      "0.0 0.68776196\n",
      "-1.0 0.69171405\n",
      "2.0 0.6762772\n",
      "1.0 -1.2263917\n",
      "-1.0 -0.6966732\n",
      "-1.0 -0.28175277\n",
      "0.0 0.03235094\n",
      "-1.0 -0.18933384\n",
      "1.0 -0.009654719\n",
      "0.0 0.71664995\n",
      "0.0 -0.32056007\n",
      "-0.0 0.25013825\n",
      "0.0 0.04837297\n",
      "-0.0 1.8536117\n",
      "1.0 0.7521839\n",
      "-0.0 1.0457932\n",
      "1.0 -0.74617344\n",
      "-0.0 -1.9257301\n",
      "1.0 -0.5345563\n",
      "-0.0 -0.12263942\n",
      "-0.0 -0.32302907\n",
      "1.0 0.7062133\n",
      "1.0 -1.4876468\n",
      "1.0 -0.010815922\n",
      "1.0 0.10818514\n",
      "-1.0 -0.4449298\n",
      "0.0 0.7753014\n",
      "0.0 0.09500334\n",
      "-1.0 0.13085434\n",
      "-1.0 -0.038242683\n",
      "-1.0 0.0747798\n",
      "1.0 0.35022503\n",
      "1.0 0.38819957\n",
      "-0.0 1.3900424\n",
      "0.0 0.66410476\n",
      "0.0 -0.5432593\n",
      "1.0 -1.1752251\n",
      "1.0 0.6062986\n",
      "1.0 -1.063453\n",
      "-2.0 0.44151413\n",
      "-0.0 -1.1420357\n",
      "-0.0 1.0074061\n",
      "-1.0 -0.6814876\n",
      "-0.0 0.000908817\n",
      "-1.0 -0.32636\n",
      "-2.0 -0.27636924\n",
      "-2.0 -1.7395835\n",
      "-0.0 -0.028901229\n",
      "-1.0 -1.2853506\n",
      "-1.0 -0.39669117\n",
      "-0.0 -0.021398678\n",
      "0.0 -0.20511198\n",
      "1.0 0.07390039\n",
      "-0.0 0.687589\n",
      "-0.0 -0.5096397\n",
      "-0.0 -0.5898345\n",
      "-0.0 -0.23843518\n",
      "2.0 -0.41232517\n",
      "-0.0 -0.6927537\n",
      "0.0 -0.100083485\n",
      "0.0 -0.58694637\n",
      "-1.0 -0.29154035\n",
      "-1.0 -0.5367192\n",
      "1.0 0.6943257\n",
      "1.0 0.20792462\n",
      "-1.0 0.12238958\n",
      "1.0 -0.14065698\n",
      "0.0 -0.9581245\n",
      "-1.0 0.09083661\n",
      "-2.0 0.12920739\n",
      "0.0 0.80935097\n",
      "2.0 1.5585619\n",
      "-1.0 0.23798259\n",
      "-0.0 -1.0721102\n",
      "-0.0 1.5699822\n",
      "-1.0 -0.25560305\n",
      "1.0 -0.942748\n",
      "0.0 -1.2399393\n",
      "-2.0 1.665127\n",
      "-1.0 1.7820752\n",
      "1.0 1.4761237\n",
      "1.0 -0.21077177\n",
      "-0.0 -2.657267\n",
      "0.0 -2.3330722\n",
      "0.0 0.69657654\n",
      "1.0 1.4550165\n",
      "-1.0 -1.7301626\n",
      "-0.0 0.5831346\n",
      "-0.0 -0.48219788\n",
      "-1.0 -0.1674442\n",
      "-1.0 1.1431518\n",
      "-1.0 0.37199047\n",
      "1.0 0.84318715\n",
      "-0.0 -0.9212614\n",
      "-1.0 -0.74867016\n",
      "1.0 0.81087166\n",
      "-1.0 0.607763\n",
      "1.0 1.1782877\n",
      "0.0 1.4816618\n",
      "-2.0 0.09993411\n",
      "0.0 0.93903005\n",
      "0.0 -1.4585057\n",
      "-1.0 -0.5984496\n",
      "0.0 -0.15061992\n",
      "-1.0 0.6417002\n",
      "-0.0 1.4247222\n",
      "-0.0 1.1478896\n",
      "0.0 -0.42283237\n",
      "-1.0 0.42882317\n",
      "1.0 -1.248352\n",
      "1.0 -1.1129662\n",
      "0.0 -0.47418764\n",
      "0.0 -0.7305471\n",
      "0.0 0.7551035\n",
      "-0.0 0.9905761\n",
      "-1.0 -1.8382509\n",
      "0.0 0.010156988\n",
      "1.0 -1.9089521\n",
      "-1.0 0.57649875\n",
      "-0.0 0.41877633\n",
      "-0.0 0.6392653\n",
      "-1.0 0.5211014\n",
      "-0.0 0.39916214\n",
      "-0.0 0.58150136\n",
      "0.0 -1.4326309\n",
      "0.0 1.9491544\n",
      "1.0 -1.5930346\n",
      "-0.0 -1.1729203\n",
      "-0.0 -0.9561233\n",
      "0.0 0.7188619\n",
      "-0.0 -0.8333345\n",
      "0.0 -0.8681835\n",
      "-0.0 0.4727493\n",
      "0.0 -1.4025494\n",
      "-1.0 1.1866256\n",
      "0.0 -0.46158355\n",
      "0.0 0.41696513\n",
      "-0.0 -1.3678006\n",
      "0.0 -1.3408641\n",
      "-0.0 -0.26934218\n",
      "-0.0 -0.67185676\n",
      "-1.0 0.2109647\n",
      "1.0 -0.056873005\n",
      "1.0 -2.3014317\n",
      "0.0 -0.1654463\n",
      "0.0 0.317326\n",
      "-0.0 -0.027383648\n",
      "-0.0 0.79074126\n",
      "0.0 1.2004656\n",
      "-1.0 0.61316025\n",
      "-0.0 -1.0995734\n",
      "-0.0 -0.3043889\n",
      "2.0 -2.1623616\n",
      "1.0 -0.9065865\n",
      "1.0 -0.07955437\n",
      "1.0 -0.3187572\n",
      "-0.0 -0.16610415\n",
      "-0.0 0.08838548\n",
      "2.0 0.4957487\n",
      "-0.0 -0.6574725\n",
      "2.0 -0.14073382\n",
      "1.0 -0.5979169\n",
      "2.0 0.8161077\n",
      "1.0 -0.55334103\n",
      "0.0 0.04829504\n",
      "0.0 -1.5251802\n",
      "1.0 0.9059521\n",
      "1.0 1.6967659\n",
      "-0.0 -0.9807595\n",
      "1.0 0.5410252\n",
      "2.0 -0.6381629\n",
      "-0.0 0.31777838\n",
      "1.0 -0.745226\n",
      "-0.0 0.94503695\n",
      "-0.0 -1.6765785\n",
      "-0.0 -1.1953605\n",
      "-0.0 0.41490605\n",
      "2.0 -0.37981787\n",
      "0.0 1.7915673\n",
      "1.0 0.2810152\n",
      "1.0 1.1771718\n",
      "2.0 0.26397738\n",
      "-0.0 -0.8476098\n",
      "0.0 0.096663594\n",
      "-0.0 -0.64805746\n",
      "-1.0 0.30300382\n",
      "-0.0 1.6106471\n",
      "1.0 -0.5604518\n",
      "-1.0 -0.7388373\n",
      "0.0 -0.43878478\n",
      "1.0 -0.60973084\n",
      "1.0 0.42901072\n",
      "1.0 1.2727032\n",
      "1.0 -0.81847936\n",
      "1.0 -0.8456226\n",
      "2.0 0.5368874\n",
      "-0.0 -1.2630898\n",
      "-1.0 1.0396752\n",
      "1.0 1.0653867\n",
      "0.0 0.30665833\n",
      "1.0 -1.1244454\n",
      "0.0 -1.2146972\n",
      "0.0 -0.52531046\n",
      "-1.0 1.0315115\n",
      "1.0 0.73840886\n",
      "0.0 0.5742112\n",
      "-0.0 0.44810498\n",
      "-0.0 -1.0877686\n",
      "2.0 0.04149534\n",
      "2.0 -1.0185864\n",
      "0.0 0.33468354\n",
      "1.0 1.3408251\n",
      "1.0 -0.12290293\n",
      "0.0 -1.2060218\n",
      "-1.0 0.80818725\n",
      "1.0 1.1310867\n",
      "0.0 -0.06929304\n",
      "2.0 2.397923\n",
      "0.0 -0.78133327\n",
      "-0.0 -0.25702783\n",
      "-0.0 -1.2832786\n",
      "-0.0 -1.1345528\n",
      "1.0 0.044690505\n",
      "-0.0 0.16689086\n",
      "0.0 1.492499\n",
      "1.0 1.5785142\n",
      "1.0 -1.0807469\n",
      "-1.0 0.74202365\n",
      "-1.0 0.58545065\n",
      "1.0 -1.5881271\n",
      "-0.0 -1.3996462\n",
      "1.0 -0.9837058\n",
      "-0.0 2.4117475\n",
      "1.0 1.4270767\n",
      "1.0 1.2643241\n",
      "1.0 0.30737677\n",
      "-0.0 0.3826239\n",
      "0.0 -1.278835\n",
      "0.0 -1.4082565\n",
      "1.0 0.36705393\n",
      "1.0 0.4576225\n",
      "-1.0 1.5436288\n",
      "0.0 0.41165063\n",
      "-0.0 -1.1417117\n",
      "-0.0 -1.0503858\n",
      "-1.0 -0.5105753\n",
      "-0.0 0.75961965\n",
      "-0.0 -0.41453376\n",
      "-0.0 -0.7945879\n",
      "-0.0 0.64271736\n",
      "-0.0 0.64699376\n",
      "-0.0 -2.2299645\n",
      "-1.0 1.0902418\n",
      "1.0 -1.085687\n",
      "-2.0 0.35384673\n",
      "-0.0 -0.24563909\n",
      "1.0 0.24081224\n",
      "0.0 -0.60161245\n",
      "0.0 -0.12699585\n",
      "2.0 0.5454406\n",
      "0.0 -0.22201875\n",
      "0.0 0.140452\n",
      "-0.0 0.6162761\n",
      "-0.0 -0.88264024\n",
      "-0.0 0.8241139\n",
      "-0.0 -0.78402174\n",
      "1.0 0.22750622\n",
      "1.0 2.0776367\n",
      "-0.0 -0.502729\n",
      "3.0 0.25877705\n",
      "1.0 0.31606135\n",
      "-1.0 2.2039635\n",
      "-0.0 1.3629936\n",
      "-1.0 -0.35005847\n",
      "-0.0 -0.11656692\n",
      "1.0 -1.4205827\n",
      "-1.0 0.15899976\n",
      "0.0 0.07147067\n",
      "1.0 -1.1317241\n",
      "1.0 1.7466588\n",
      "0.0 0.68379915\n",
      "2.0 -1.4571\n",
      "0.0 -1.8848879\n",
      "-1.0 0.15498514\n",
      "0.0 2.8733974\n",
      "0.0 0.8142332\n",
      "2.0 1.0661967\n",
      "1.0 -0.648869\n",
      "-1.0 0.18048134\n",
      "0.0 0.050112277\n",
      "-0.0 0.73507696\n",
      "-0.0 1.4303583\n",
      "1.0 -0.32862544\n",
      "0.0 -0.77672386\n",
      "-0.0 0.5410858\n",
      "0.0 -0.42271978\n",
      "1.0 -0.96560144\n",
      "0.0 0.32385224\n",
      "-0.0 0.36466584\n",
      "1.0 0.6027359\n",
      "-0.0 1.2161922\n",
      "0.0 -1.129237\n",
      "1.0 -2.0345402\n",
      "1.0 1.0042975\n",
      "0.0 0.18394776\n",
      "1.0 0.41890728\n",
      "1.0 0.2564723\n",
      "1.0 0.99128723\n",
      "0.0 -0.055746835\n",
      "-0.0 1.7677965\n",
      "-1.0 0.2644759\n",
      "-0.0 -1.0612543\n",
      "-1.0 -0.9456605\n",
      "0.0 0.09873516\n",
      "-0.0 1.2903079\n",
      "1.0 -0.1771274\n",
      "0.0 -0.84119785\n",
      "-0.0 -0.38789085\n",
      "-2.0 -0.40641162\n",
      "0.0 0.29858994\n",
      "-0.0 -0.4570177\n",
      "0.0 0.6468303\n",
      "0.0 -3.4302168\n",
      "0.0 -2.0863006\n",
      "1.0 0.018063374\n",
      "0.0 0.037877075\n",
      "-1.0 0.1525597\n",
      "-1.0 0.29618406\n",
      "-1.0 0.23907928\n",
      "1.0 0.66471297\n",
      "1.0 0.7856114\n",
      "1.0 0.7146995\n",
      "-1.0 0.055646364\n",
      "-2.0 -0.9645042\n",
      "-1.0 0.46054798\n",
      "0.0 0.095863946\n",
      "1.0 1.4877714\n",
      "1.0 0.5200303\n",
      "-1.0 -0.7825296\n",
      "-2.0 0.96420467\n",
      "0.0 0.48555866\n",
      "0.0 0.225547\n",
      "1.0 -0.03472488\n",
      "0.0 -0.43486258\n",
      "-0.0 -1.1230248\n",
      "1.0 -0.66270506\n",
      "0.0 1.9794319\n",
      "1.0 -0.66524523\n",
      "-0.0 0.8749252\n",
      "0.0 0.11891368\n",
      "1.0 -0.61561984\n",
      "1.0 0.89828235\n",
      "-0.0 -1.1416931\n",
      "-1.0 1.3181298\n",
      "-0.0 -0.9420929\n",
      "0.0 -0.463069\n",
      "1.0 1.3531809\n",
      "1.0 -0.29476884\n",
      "1.0 -0.12387152\n",
      "2.0 1.9820005\n",
      "0.0 -0.4738546\n",
      "-0.0 0.16350016\n",
      "1.0 0.2855942\n",
      "-1.0 -0.6688408\n",
      "1.0 -0.8085339\n",
      "-0.0 1.3047657\n",
      "2.0 0.78125733\n",
      "1.0 1.4511508\n",
      "1.0 -0.5858052\n",
      "-1.0 1.5157183\n",
      "2.0 -0.24320522\n",
      "3.0 -0.21862224\n",
      "-1.0 -0.35945055\n",
      "0.0 0.424277\n",
      "Accuracy:  0.0\n"
     ]
    }
   ],
   "source": [
    "# Prediction of builds using our neural network \n",
    "total_samples = test_y.shape[0]\n",
    "correct = 0 \n",
    "print(total_samples)\n",
    "for t in range(total_samples) : \n",
    "    prediction = net(test_X[t]).detach().numpy()\n",
    "    prediction = round (prediction[0]) \n",
    "    print(prediction,test_y[t].numpy()[0])\n",
    "    if prediction == test_y[t].numpy()[0] : \n",
    "        correct +=1 \n",
    "print(\"Accuracy: \" , (correct/total_samples)*100) \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
